{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os, sys, random\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.18 🚀 Python-3.10.6 torch-2.3.0 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=helmet.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train18, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train18\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train18', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/iliyask/Helmet_iliyas/helmet_det/Data/labels/train.cache... 6139 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6139/6139 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000002.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000003.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000007.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000011.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000068.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000091.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000106.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000113.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000153.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000158.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000168.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000177.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000184.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000226.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000267.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000268.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000284.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000291.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000320.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000393.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000433.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000457.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000512.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000514.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000548.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000565.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000599.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000686.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000687.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000734.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000796.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000797.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000798.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000799.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000815.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000820.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000827.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000909.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/000985.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/001042.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/001046.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/001150.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/001354.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/001386.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/001387.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/part2_000878.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/part2_001363.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/train/part2_001696.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/iliyask/Helmet_iliyas/helmet_det/Data/labels/val.cache... 683 images, 0 backgrounds, 0 corrupt: 100%|██████████| 683/683 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/000061.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/000173.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/000274.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/000290.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/000528.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/000601.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/000640.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/001358.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/part2_001057.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /Users/iliyask/Helmet_iliyas/helmet_det/Data/images/val/part2_001825.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train18/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train18\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/384 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 nano model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Train the model using the specified dataset and number of epochs\n",
    "results = model.train(data=\"helmet.yaml\", epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = YOLO('yolo_v8_25.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to grab frame\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 hats, 1 person, 65.2ms\n",
      "Speed: 3.3ms preprocess, 65.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'Results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m detection \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m---> 20\u001b[0m         x1, y1, x2, y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, detection[:\u001b[38;5;241m4\u001b[39m])  \u001b[38;5;66;03m# Bounding box coordinates\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         conf \u001b[38;5;241m=\u001b[39m detection[\u001b[38;5;241m4\u001b[39m]  \u001b[38;5;66;03m# Confidence score\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         class_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detection[\u001b[38;5;241m5\u001b[39m])  \u001b[38;5;66;03m# Class ID\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'Results'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)  # Change the argument to 1 if 0 doesn't work\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Process the video stream\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform inference on the frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # Draw the bounding boxes and labels on the frame\n",
    "    for result in results:\n",
    "        for detection in result:\n",
    "            x1, y1, x2, y2 = map(int, detection[:4])  # Bounding box coordinates\n",
    "            conf = detection[4]  # Confidence score\n",
    "            class_id = int(detection[5])  # Class ID\n",
    "\n",
    "            label = f\"{model.names[class_id]} {conf:.2f}\"\n",
    "            color = (0, 255, 0)  # Bounding box color (green)\n",
    "\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            # Draw the label\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"YOLOv5 Real-Time Detection\", frame)\n",
    "\n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "import cv2\n",
    "cam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"test\")\n",
    "img_counter = 0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    cv2.imshow(\"test\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helmet_det",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
